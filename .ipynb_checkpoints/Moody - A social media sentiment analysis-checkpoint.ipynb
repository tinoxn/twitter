{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import preprocessor as p\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "train = pd.read_csv(\"SentimentDataset_train.csv\")\n",
    "\n",
    "# testing data\n",
    "test = pd.read_csv(\"SentimentDataset_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good sentiment related tweets\n",
    "sum(train[\"label\"] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad sentiment related tweets\n",
    "sum(train[\"label\"] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are any missing values\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up punctuations we want to be replaced\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\|)|(\\()|(\\))|(\\[)|(\\])|(\\%)|(\\$)|(\\>)|(\\<)|(\\{)|(\\})\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s/><br\\s/?)|(-)|(/)|(:).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(df):\n",
    "    tempArr = []\n",
    "    for line in df:\n",
    "        # clean using tweet_preprocessor\n",
    "        tmpL = p.clean(line)\n",
    "        # remove all punctuation\n",
    "        tmpL = REPLACE_NO_SPACE.sub(\"\", tmpL.lower())\n",
    "        tmpL = REPLACE_WITH_SPACE.sub(\" \", tmpL)\n",
    "        tempArr.append(tmpL)\n",
    "    return tempArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean training data\n",
    "train_tweet = clean_tweets(train[\"tweet\"])\n",
    "train_tweet = pd.DataFrame(train_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append cleaned tweets to the training dataset\n",
    "train[\"clean_tweet\"] = train_tweet\n",
    "\n",
    "# display the new dataset\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean training data\n",
    "test_tweet = clean_tweets(test[\"tweet\"])\n",
    "test_tweet = pd.DataFrame(test_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append cleaned tweets to the test dataset\n",
    "test[\"clean_tweet\"] = test_tweet\n",
    "\n",
    "# display the new dataset\n",
    "test.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the labels from the train data\n",
    "y = train.label.values\n",
    "\n",
    "# use 70% for the training and 30% for the test\n",
    "x_train, x_test, y_train, y_test = train_test_split(train.clean_tweet.values, y,\n",
    "                                                   stratify = y,\n",
    "                                                   random_state = 1,\n",
    "                                                   test_size = 0.3,\n",
    "                                                   shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize tweets using CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initilizing the CountVectorizer()\n",
    "vectorizer = CountVectorizer(binary = True, stop_words = \"english\")\n",
    "\n",
    "# learn a vocabulary dictionary of all tokens in the raw documents\n",
    "vectorizer.fit(list(x_train) + list(x_test))\n",
    "\n",
    "# transfrom documents to document-term matrix\n",
    "x_train_vec = vectorizer.transform(x_train)\n",
    "x_test_vec = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# We shall apply Support Vector Classifier (SVC)\n",
    "svm = svm.SVC(kernel = \"linear\", probability = True)\n",
    "\n",
    "# fit the SVC model based on the given training data\n",
    "svm.fit(x_train_vec, y_train).predict_proba(x_test_vec)\n",
    "\n",
    "# perform classification and prediction on samples in x_test\n",
    "y_pred_svm = svm.predict(x_test_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy score for SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy score for SVC is:\", accuracy_score(y_test, y_pred_svm) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# We will use Pickel package to assist us saving our model as a file\n",
    "filename = 'moody_sentiment_model.sav'\n",
    "pickle.dump(svm, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
